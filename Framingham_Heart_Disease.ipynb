{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
        "from sklearn.utils import resample\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "iY7uH4h4ufgU"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"framingham.csv\")"
      ],
      "metadata": {
        "id": "SilH9diU_ltG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling missing values using imputation strategies\n",
        "mean_imputer = SimpleImputer(strategy='mean')\n",
        "mean_cols = ['heartRate']\n",
        "data[mean_cols] = mean_imputer.fit_transform(data[mean_cols])\n",
        "\n",
        "median_imputer = SimpleImputer(strategy='median')\n",
        "median_cols = ['education', 'cigsPerDay', 'BPMeds', 'totChol', 'BMI', 'glucose']\n",
        "data[median_cols] = median_imputer.fit_transform(data[median_cols])"
      ],
      "metadata": {
        "id": "YMQxY-Mby1bs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_outliers_with_IQR(df, column):\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    df[column] = df[column].clip(lower=lower_bound, upper=upper_bound)\n",
        "\n",
        "continuous_cols = ['age', 'cigsPerDay', 'totChol', 'sysBP', 'diaBP', 'BMI', 'heartRate', 'glucose']\n",
        "for col in continuous_cols:\n",
        "    handle_outliers_with_IQR(data, col)"
      ],
      "metadata": {
        "id": "uMi_SHiNxpN7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_column = 'TenYearCHD'\n",
        "data_majority = data[data[target_column] == 0]\n",
        "data_minority = data[data[target_column] == 1]\n",
        "data_minority_upsampled = resample(data_minority, replace=True, n_samples=len(data_majority), random_state=123)\n",
        "data_upsampled = pd.concat([data_majority, data_minority_upsampled])"
      ],
      "metadata": {
        "id": "DdUpuHJix6MT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data_upsampled.drop(target_column, axis=1)\n",
        "y = data_upsampled[target_column]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "0N_tLWhRzDdr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_confusion_matrix(y_test, y_pred):\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    num_classes = len(cm)\n",
        "\n",
        "    # Print confusion matrix header\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(\"True Labels ->\")\n",
        "    print(\"Predicted Labels v\")\n",
        "    print(f\"{'':<10}\", end=\"\")\n",
        "    for i in range(num_classes):\n",
        "        print(f\"{i:<10}\", end=\"\")\n",
        "    print()\n",
        "\n",
        "    # Print confusion matrix contents\n",
        "    for i in range(num_classes):\n",
        "        print(f\"{i:<10}\", end=\"\")\n",
        "        for j in range(num_classes):\n",
        "            print(f\"{cm[i][j]:<10}\", end=\"\")\n",
        "        print()"
      ],
      "metadata": {
        "id": "4CdacwGu1PdU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "def Metrics(y_test, y_pred, y_pred_proba):\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "    # Create dictionary to store metrics\n",
        "    metrics_dict = {\n",
        "        'Accuracy': round(accuracy*100, 4),\n",
        "        'Precision': round(precision*100, 4),\n",
        "        'Recall': round(recall*100, 4),\n",
        "        'F1': round(f1*100, 4),\n",
        "        'AUC': round(auc*100, 4)\n",
        "    }\n",
        "\n",
        "    # Print the metrics dictionary neatly\n",
        "    print(\"\\nClassification Metrics:\")\n",
        "    for metric, value in metrics_dict.items():\n",
        "        print(f\"{metric} Score: [{value}] %\")\n",
        "\n",
        "    return metrics_dict"
      ],
      "metadata": {
        "id": "WtD9KlHVAH-m"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the XGBoost classifier\n",
        "xgb_classifier = XGBClassifier(random_state=42)\n",
        "\n",
        "# Train the model\n",
        "xgb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = xgb_classifier.predict(X_test)\n",
        "y_prob = xgb_classifier.predict_proba(X_test)[:,1]\n",
        "\n",
        "# Evaluate the model\n",
        "print_confusion_matrix(y_test, y_pred)\n",
        "Metrics(y_test,y_pred ,y_prob)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFJ5rdMSzQNu",
        "outputId": "56b56713-0cfb-4f51-82c5-6800cef268f9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Confusion Matrix:\n",
            "True Labels ->\n",
            "Predicted Labels v\n",
            "          0         1         \n",
            "0         657       96        \n",
            "1         11        674       \n",
            "\n",
            "Classification Metrics:\n",
            "Accuracy Score: [92.5591] %\n",
            "Precision Score: [87.5325] %\n",
            "Recall Score: [98.3942] %\n",
            "F1 Score: [92.646] %\n",
            "AUC Score: [97.9343] %\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy': 92.5591,\n",
              " 'Precision': 87.5325,\n",
              " 'Recall': 98.3942,\n",
              " 'F1': 92.646,\n",
              " 'AUC': 97.9343}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "clf = ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "y_prob = clf.predict_proba(X_test)[:,1]\n",
        "\n",
        "# Evaluate the model\n",
        "print_confusion_matrix(y_test, y_pred)\n",
        "Metrics(y_test,y_pred ,y_prob)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBcjzJQi5rSb",
        "outputId": "3528f35d-3ffa-4ab4-a062-1f609c26b0c7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Confusion Matrix:\n",
            "True Labels ->\n",
            "Predicted Labels v\n",
            "          0         1         \n",
            "0         744       9         \n",
            "1         8         677       \n",
            "\n",
            "Classification Metrics:\n",
            "Accuracy Score: [98.8178] %\n",
            "Precision Score: [98.688] %\n",
            "Recall Score: [98.8321] %\n",
            "F1 Score: [98.76] %\n",
            "AUC Score: [99.569] %\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy': 98.8178,\n",
              " 'Precision': 98.688,\n",
              " 'Recall': 98.8321,\n",
              " 'F1': 98.76,\n",
              " 'AUC': 99.569}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier(random_state=0)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "y_prob = clf.predict_proba(X_test)[:,1]\n",
        "\n",
        "# Evaluate the model\n",
        "print_confusion_matrix(y_test, y_pred)\n",
        "Metrics(y_test,y_pred ,y_prob)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbKSmQJz6TU8",
        "outputId": "039c335e-0d5f-4438-ce0b-b92897a6a79b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Confusion Matrix:\n",
            "True Labels ->\n",
            "Predicted Labels v\n",
            "          0         1         \n",
            "0         719       34        \n",
            "1         7         678       \n",
            "\n",
            "Classification Metrics:\n",
            "Accuracy Score: [97.1488] %\n",
            "Precision Score: [95.2247] %\n",
            "Recall Score: [98.9781] %\n",
            "F1 Score: [97.0651] %\n",
            "AUC Score: [99.4743] %\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy': 97.1488,\n",
              " 'Precision': 95.2247,\n",
              " 'Recall': 98.9781,\n",
              " 'F1': 97.0651,\n",
              " 'AUC': 99.4743}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "clf = LinearDiscriminantAnalysis()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "y_prob = clf.predict_proba(X_test)[:,1]\n",
        "\n",
        "# Evaluate the model\n",
        "print_confusion_matrix(y_test, y_pred)\n",
        "Metrics(y_test,y_pred ,y_prob)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPm-ruj8_1-j",
        "outputId": "43180b07-510d-4609-988b-f67ec7926cad"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Confusion Matrix:\n",
            "True Labels ->\n",
            "Predicted Labels v\n",
            "          0         1         \n",
            "0         486       267       \n",
            "1         189       496       \n",
            "\n",
            "Classification Metrics:\n",
            "Accuracy Score: [68.2893] %\n",
            "Precision Score: [65.0066] %\n",
            "Recall Score: [72.4088] %\n",
            "F1 Score: [68.5083] %\n",
            "AUC Score: [73.5367] %\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy': 68.2893,\n",
              " 'Precision': 65.0066,\n",
              " 'Recall': 72.4088,\n",
              " 'F1': 68.5083,\n",
              " 'AUC': 73.5367}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "clf = LogisticRegression()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "y_prob = clf.predict_proba(X_test)[:,1]\n",
        "\n",
        "# Evaluate the model\n",
        "print_confusion_matrix(y_test, y_pred)\n",
        "Metrics(y_test,y_pred ,y_prob)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whcNKrpSAnc4",
        "outputId": "9329ba45-ef53-4da5-c260-1aaf82b4ce03"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Confusion Matrix:\n",
            "True Labels ->\n",
            "Predicted Labels v\n",
            "          0         1         \n",
            "0         459       294       \n",
            "1         232       453       \n",
            "\n",
            "Classification Metrics:\n",
            "Accuracy Score: [63.4214] %\n",
            "Precision Score: [60.6426] %\n",
            "Recall Score: [66.1314] %\n",
            "F1 Score: [63.2682] %\n",
            "AUC Score: [69.9803] %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy': 63.4214,\n",
              " 'Precision': 60.6426,\n",
              " 'Recall': 66.1314,\n",
              " 'F1': 63.2682,\n",
              " 'AUC': 69.9803}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}